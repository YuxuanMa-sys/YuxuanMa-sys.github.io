---
layout: default
title: "Enhancing Code Reasoning and Test Generation in DeepSeekCoder (Python)"
---

## Project Overview
**Dates:** August 2024 â€“ December 2024  
**Affiliation:** University of Illinois Urbana-Champaign

We addressed the challenge of limited accuracy in code reasoning and test generation by exploring how **tailored prompts** can guide large language models to produce syntactically correct and logically accurate outputs.

- **Issues Identified**
    - Misinterpretation of task structure
    - Incorrect function naming
    - Poor handling of complex control flows or implicit input validations

- **Prompt Engineering Approach**
    - Designed crafted prompts with explicit task instructions, a modular structure, and labeled sections for both code and expected outputs
    - Employed iterative experimentation to refine prompts, improving model comprehension and reducing errors in generated code

- **Results**
    - Achieved a **50% improvement** in prediction accuracy
    - Realized a **20% increase** in test coverage
    - Demonstrated the potential of structured prompt engineering to enhance AI reasoning in software development

### Skills
- Prompt Engineering
- Artificial Intelligence (AI)
- AI Prompting
- Teamwork
- Time Management

### Links & Resources
- **GitHub Repository**: [DeepSeekCoder Repo](https://github.com/YuxuanMa-sys/CS598JBR-Team-16)
- **Project Report**: [CS598.JBR Report](../assets/deepseekcoder_report.pdf)

